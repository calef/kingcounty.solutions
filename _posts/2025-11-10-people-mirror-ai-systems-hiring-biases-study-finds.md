---
date: '2025-11-10T15:46:33+00:00'
images: []
published: false
source: University of Washington
source_url: https://www.washington.edu/news/2025/11/10/people-mirror-ai-systems-hiring-biases-study-finds/
summarized: true
title: People mirror AI systemsâ€™ hiring biases, study finds
topics: []
---

A study by the University of Washington found that human hiring decisions closely mirror the biases present in artificial intelligence (AI) systems. Involving 528 participants who evaluated candidates for various jobs, the research simulated different levels of racial bias in AI recommendations. When participants made hiring decisions without AI assistance or with neutral AI, their choices showed little bias. However, when using a moderately biased AI, participants adopted the AI's preferences, favoring non-white candidates if the AI did, and vice versa. In cases of severe bias, participants' decisions aligned nearly 90% with the AI's recommendations.

The study highlights a concerning trend where human judgment is influenced by AI biases, especially if those biases are not overtly recognized. Participants were provided with resumes suggesting racial backgrounds, and those exposed to AI recommendations exhibited significantly biased decision-making. The research suggests that incorporating implicit association tests in training could help reduce biases, indicating that both awareness and the design of AI systems are critical for fair hiring practices. The findings were presented at the AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society in Madrid.
