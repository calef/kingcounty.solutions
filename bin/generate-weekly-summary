#!/usr/bin/env ruby
# frozen_string_literal: true

require 'date'
require 'fileutils'
require 'json'
require 'ruby/openai'
require 'time'
require 'yaml'
require_relative '../lib/logging'

ROOT = File.expand_path('..', __dir__)
POSTS_DIR = File.join(ROOT, '_posts')

DEFAULT_MODEL = ENV.fetch('OPENAI_MODEL', 'gpt-5.1')
LLM_MAX_POSTS = ENV.fetch('WEEKLY_SUMMARY_LIMIT', '60').to_i
LOGGER = Logging.build_logger(env_var: 'LOG_LEVEL')

def current_week_range(today = Date.today)
  days_since_saturday = (today.wday - 6) % 7
  week_end = today - days_since_saturday
  week_start = week_end - 6
  [week_start, week_end]
end

def parse_front_matter(text)
  return [nil, nil] unless text.start_with?('---')

  parts = text.split(/^---\s*$\n?/, 3)
  return [nil, nil] unless parts.length >= 3

  data = YAML.safe_load(parts[1]) || {}
  body = parts[2].strip
  [data, body]
rescue Psych::SyntaxError => e
  LOGGER.warn "Failed to parse front matter: #{e.message}"
  [nil, nil]
end

def normalize_excerpt(body)
  paragraphs = body.split(/\n{2,}/).map(&:strip).reject(&:empty?)
  excerpt = paragraphs.first(3).join(' ')
  excerpt.gsub(/\s+/, ' ')[0..900]
end

def weekly_posts(start_date, end_date)
  Dir.glob(File.join(POSTS_DIR, '*.md')).each_with_object([]) do |path, memo|
    basename = File.basename(path)
    match = basename.match(/\A(\d{4}-\d{2}-\d{2})-/)
    next unless match

    post_date = Date.parse(match[1])
    next unless post_date >= start_date && post_date <= end_date

    raw = File.read(path)
    data, body = parse_front_matter(raw)
    next unless data
    next if data['published'] == false

    memo << {
      id: basename,
      file: basename,
      slug: basename.sub(/\A\d{4}-\d{2}-\d{2}-/, '').sub(/\.md\z/, ''),
      path: path,
      date: post_date,
      title: data['title'] || basename,
      source: data['source'] || 'Unknown source',
      source_url: data['source_url'],
      summary: normalize_excerpt(body || '')
    }
  end.sort_by { |post| [post[:date], post[:title]] }
end

def build_context(posts, start_date, end_date, plan)
  lookup = posts.map { |p| [p[:id], post_payload(p)] }.to_h
  counts = Hash.new(0)
  posts.each { |post| counts[post[:source]] += 1 }
  top_sources = counts.sort_by { |_k, v| -v }.first(10).map { |source, count| { 'source' => source, 'count' => count } }

  themes = plan['themes'].map do |theme|
    {
      'title' => theme['title'],
      'summary' => theme['summary'],
      'posts' => theme['post_ids'].map { |id| lookup[id] }.compact
    }
  end

  {
    'window' => {
      'start' => start_date.to_s,
      'end' => end_date.to_s
    },
    'post_count' => posts.length,
    'top_sources' => top_sources,
    'themes' => themes,
    'other_posts' => plan.fetch('other_ids', []).map { |id| lookup[id] }.compact,
    'catalog' => lookup,
    'theme_plan' => plan
  }
end

def post_payload(post)
  {
    'id' => post[:id],
    'title' => post[:title],
    'date' => post[:date].to_s,
    'source' => post[:source],
    'url' => post[:source_url],
    'source_url' => post[:source_url],
    'summary' => post[:summary]
  }
end

def build_theme_plan(posts)
  sample_posts = posts.first(LLM_MAX_POSTS).map { |p| post_payload(p) }
  prompt = <<~PROMPT
    You are clustering weekly civic updates into editorial themes.
    Given the JSON array of posts below, create 3-4 high-level themes that capture the major narratives.
    Requirements:
      * Return a JSON object with keys:
          - "themes": array of objects { "title": string, "summary": string, "post_ids": [post_id, ...] }. Each theme should reference at least two unique post_ids.
          - "other_ids": array of remaining post_ids that didn't fit the main themes.
      * Keep titles concise (max 60 chars) and summaries under 200 chars.
      * Use each post_id at most once across themes + other_ids.
      * Prefer grouping by narrative impact rather than source.
      * Respond with JSON only.

    POSTS JSON:
    #{JSON.pretty_generate(sample_posts)}
  PROMPT

  raw = call_llm_chat(
    [
      { role: 'system', content: 'You analyze civic news items and cluster them into weekly themes.' },
      { role: 'user', content: prompt }
    ],
    temperature: 0.2
  )
  sanitized = strip_markdown_code_fence(raw)
  JSON.parse(sanitized)
rescue StandardError => e
  LOGGER.warn "Theme planning failed (#{e.message}). Using fallback themes."
  fallback_theme_plan(posts)
end

def fallback_theme_plan(posts)
  post_ids = posts.first(LLM_MAX_POSTS).map { |p| p[:id] }
  {
    'themes' => [
      {
        'title' => 'Key regional updates',
        'summary' => 'Highlights across public safety, infrastructure, and community programs.',
        'post_ids' => post_ids.first(6)
      }
    ],
    'other_ids' => post_ids.drop(6)
  }
end

def strip_markdown_code_fence(text)
  stripped = text.strip
  return stripped unless stripped.start_with?('```')

  lines = stripped.lines
  lines.shift # remove opening fence
  # remove closing fence if present
  lines.pop if lines.last&.strip == '```'
  lines.join.strip
end

def openai_client
  @openai_client ||= OpenAI::Client.new(access_token: ENV.fetch('OPENAI_API_KEY'))
end

def call_llm_chat(messages, temperature: 0.3, model: DEFAULT_MODEL)
  response = openai_client.chat(
    parameters: {
      model: model,
      temperature: temperature,
      messages: messages
    }
  )
  if (error_message = response.dig('error', 'message'))
    raise "LLM request failed: #{error_message}"
  end
  content = response.dig('choices', 0, 'message', 'content')
  raise 'LLM response missing content' unless content
  content
end

def call_llm(prompt)
  call_llm_chat(
    [
      { role: 'system', content: 'You are a concise civic-news editor who writes weekly recaps for King County residents.' },
      { role: 'user', content: prompt }
    ],
    temperature: 0.3
  )
end

def build_prompt(context)
  <<~PROMPT
    You are the editor for King County Solutions, a site that aggregates public-sector updates for residents in King County, Washington.

    TASK:
    • Study the provided JSON payload of partner posts for the week ending #{context['window']['end']}.
    • Use the provided "themes" array to organize your section headings (one section per theme, reusing the supplied titles).
    • Use each post's `url` value for inline links.
    • Write an engaging markdown article with the following structure:
      1. An opening paragraph summarizing how many posts we published and why this week matters.
      2. One section per theme (use the provided titles). Each section should have 1–2 short paragraphs weaving together the posts listed for that theme with inline links and context on why they matter. The inline links should not be within parentheses but linked from within the text.
      3. If `other_posts` is non-empty, add a short "### Other updates" paragraph covering them.
    • Keep the tone factual yet accessible, mirroring a newsroom briefing.
    • Mention source organizations in-line where relevant.
    • Do NOT fabricate links—only use the provided URLs.
    • Avoid repeating the same post in multiple sections unless critical.
    • Do NOT include a top-level H1 heading; start directly with the opening paragraph.
    • Limit the total response to roughly 450 words.

    JSON PAYLOAD:
    #{JSON.pretty_generate(context)}
  PROMPT
end

def call_llm(prompt)
  client = OpenAI::Client.new(access_token: ENV.fetch('OPENAI_API_KEY'))
  response = client.chat(
    parameters: {
      model: DEFAULT_MODEL,
      temperature: 0.3,
      messages: [
        { role: 'system', content: 'You are a concise civic-news editor who writes weekly recaps for King County residents.' },
        { role: 'user', content: prompt }
      ]
    }
  )

  if (error_message = response.dig('error', 'message'))
    raise "LLM request failed: #{error_message}"
  end

  content = response.dig('choices', 0, 'message', 'content')
  raise 'LLM response missing content' unless content
  content
end

def fallback_summary(posts, start_date, end_date, plan = nil)
  total = posts.length
  lines = []
  lines << "We published #{total} partner update#{'s' unless total == 1} from #{start_date.strftime('%B %-d')} through #{end_date.strftime('%B %-d, %Y')}."
  plan ||= fallback_theme_plan(posts)
  lookup = posts.map { |p| [p[:id], p] }.to_h

  plan['themes'].each do |theme|
    refs = theme['post_ids'].map { |id| lookup[id] }.compact.first(4).map do |post|
      link = post[:source_url] ? "[#{post[:title]}](#{post[:source_url]})" : post[:title]
      "#{link} (#{post[:source]})"
    end
    next if refs.empty?

    lines << ''
    lines << "### #{theme['title']}"
    lines << "#{theme['summary']} Highlights: #{refs.join(', ')}."
  end

  other_refs = plan.fetch('other_ids', []).map { |id| lookup[id] }.compact.first(4).map do |post|
    link = post[:source_url] ? "[#{post[:title]}](#{post[:source_url]})" : post[:title]
    "#{link} (#{post[:source]})"
  end

  if other_refs.any?
    lines << ''
    lines << '### Other updates'
    lines << "Additional items: #{other_refs.join(', ')}."
  end

  lines.join("\n")
end

def write_summary(start_date, end_date, body, model_used)
  title = "King County Solutions Weekly Roundup: #{human_range(start_date, end_date)}"
  slug = slugify(title)
  filename = "#{end_date}-#{slug}.md"
  dest = File.join(POSTS_DIR, filename)

  timezone_offset = Time.now.utc_offset
  publish_time = Time.new(end_date.year, end_date.month, end_date.day, 18, 0, 0, timezone_offset)

  front_matter = {
    'title' => title,
    'date' => publish_time.iso8601,
    'source' => 'King County Solutions',
    'summarized' => true,
    'openai_model' => model_used
  }

  contents = +"---\n"
  contents << front_matter.to_yaml.sub(/\A---\s*\n/, '')
  contents << "---\n\n"
  contents << body
  contents << "\n\nWe’ll continue to pull the most actionable updates from partner feeds each week. Let us know if there’s a topic you’d like covered in more depth."

  File.write(dest, contents)
  dest
end

def human_range(start_date, end_date)
  start_str = start_date.strftime('%B %-d')
  end_str = end_date.strftime('%B %-d, %Y')
  "#{start_str}–#{end_str}"
end

def slugify(text)
  text.downcase
      .gsub(/[^a-z0-9]+/, '-')
      .gsub(/^-+|-+$/, '')
end

def parsed_date(date_str)
  return nil unless date_str

  Date.parse(date_str)
rescue ArgumentError
  LOGGER.warn "Invalid date format: #{date_str}. Expected YYYY-MM-DD."
  nil
end

def main
  override_date = parsed_date(ENV['WEEKLY_DATE'])
  week_reference = override_date || Date.today
  start_date, end_date = current_week_range(week_reference)
  posts = weekly_posts(start_date, end_date)

  if posts.empty?
    LOGGER.warn 'No posts found for the current week.'
    return
  end

  plan = build_theme_plan(posts)
  context = build_context(posts, start_date, end_date, plan)
  prompt = build_prompt(context)

  body, model_used = begin
    [call_llm(prompt).strip, DEFAULT_MODEL]
  rescue StandardError => e
    LOGGER.warn "LLM generation failed (#{e.message}). Falling back to heuristic summary."
    [fallback_summary(posts, start_date, end_date, plan), 'fallback']
  end

  summary_path = write_summary(start_date, end_date, body, model_used)
  LOGGER.info "Created weekly summary: #{summary_path}"
end

main if $PROGRAM_NAME == __FILE__
